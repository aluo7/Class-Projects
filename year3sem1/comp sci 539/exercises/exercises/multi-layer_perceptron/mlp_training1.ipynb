{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1427,"status":"ok","timestamp":1697325713833,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"36wZV4G372WT"},"outputs":[],"source":["import torch\n","import numpy as np\n","import random\n","import torch.nn.functional as F\n","\n","# for easier reading np\n","np.set_printoptions(precision=3,suppress=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1552,"status":"ok","timestamp":1697325715382,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"UBPzbcsME_ei","outputId":"a0d11189-0161-4cf3-93cb-3d2d81cb5d6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["X (150, 4) [5.1 3.5 1.4 0.2]\n","y (150,) 0\n","y_1hot torch.Size([150, 3]) tensor([1., 0., 0.])\n"]}],"source":["# Prepare the data\n","from sklearn import datasets\n","data = datasets.load_iris()\n","X = data.data\n","y = data.target\n","def to1hot(labels):\n","    \"\"\"Converts an array of class labels into their 1hot encodings.\n","    Assumes that there are at most three classes.\"\"\"\n","    return torch.eye(3)[labels]\n","\n","print('X', X.shape, X[0])\n","print('y', y.shape, y[0])\n","print('y_1hot', to1hot(y).shape, to1hot(y)[0])"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhWu7lJObRns","executionInfo":{"status":"ok","timestamp":1697325715796,"user_tz":300,"elapsed":418,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"outputId":"ec98074b-d397-4fd7-a5cd-676d33756f9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train torch.Size([120, 4])\n","X_test torch.Size([30, 4])\n"]}],"source":["# Partition the data into Training and Testing (80:20 split)\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n","\n","X_train, X_test = torch.from_numpy(X_train).float(), torch.from_numpy(X_test).float()\n","y_train, y_test = torch.from_numpy(y_train).int(), torch.from_numpy(y_test).int()\n","\n","print('X_train', X_train.shape)\n","print('X_test', X_test.shape)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697325715796,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"41FxqWjuDVcm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9110c8e-86cd-4598-d315-825d3b085c66"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_batch torch.Size([10, 4]) tensor([5.4000, 3.9000, 1.7000, 0.4000])\n","y_batch torch.Size([10]) tensor(0, dtype=torch.int32)\n"]}],"source":["# Reading the dataset\n","def data_iter(batch_size, features, labels):\n","    num_examples = len(features)\n","\n","    # The examples are read at random, in no particular order\n","    indices = list(range(num_examples))\n","    random.shuffle(indices)\n","    for i in range(0, num_examples, batch_size):\n","        j = indices[i:i + batch_size]\n","        yield features[j], labels[j]\n","\n","# Check data reader\n","for X_batch, y_batch in data_iter(batch_size=10, features=X_train, labels=y_train):\n","    print('X_batch', X_batch.shape, X_batch[0])\n","    print('y_batch', y_batch.shape, y_batch[0])\n","    break"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697325715796,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"XSCNT519s7xF"},"outputs":[],"source":["# Optimization algorithm: Stochastic Gradient Descent\n","def sgd(params, grads, lr):\n","    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n","    for p, g in zip(params, grads):\n","        p.data -= lr * g"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697325715797,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"oplV28fQ0ZTy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e30ff89-823f-4e65-ea40-9c8de413db39"},"outputs":[{"output_type":"stream","name":"stdout","text":["loss = tensor(1.2344)\n"]}],"source":["# Loss Function\n","def cross_entropy(y_hat, y):\n","    \"\"\"Cross Entropy Loss.\"\"\"\n","    loss_per_sample = F.cross_entropy(y_hat, y)\n","    return loss_per_sample.mean()\n","\n","# Check loss\n","loss = cross_entropy(torch.tensor([[0.2, 0.8, 0.1],[0.6, 0.3, 0.1]]), torch.tensor([0, 1]))\n","print('loss =', loss)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTtWCNDHbRnt","executionInfo":{"status":"ok","timestamp":1697325716027,"user_tz":300,"elapsed":234,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"outputId":"72e793d1-7816-468f-a4e3-b487acc5f130"},"outputs":[{"output_type":"stream","name":"stdout","text":["w tensor([[ 1.4490,  0.5984,  0.2998],\n","        [ 0.4253, -0.7106, -0.5121],\n","        [-1.0223,  0.3731,  1.1503],\n","        [-0.5052, -0.4552,  0.6248]], requires_grad=True)\n","b tensor([[ 0.8639, -0.7394,  0.6217]], requires_grad=True)\n"]}],"source":["# Initializing Model Parameters\n","w = torch.randn(4, 3, requires_grad=True)\n","b = torch.randn(1, 3, requires_grad=True)\n","print('w', w)\n","print('b', b)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697325716027,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"WVKNCTXuBB9A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"03162a4b-e7cd-45de-aa72-e9c8489cb97c"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_batch torch.Size([10, 4]) tensor([6.7000, 3.3000, 5.7000, 2.1000])\n","out_batch torch.Size([10, 3]) tensor([0.0236, 0.0012, 0.9752], grad_fn=<SelectBackward0>)\n"]}],"source":["# Implement the model\n","def model(X, w, b):\n","    # Single Neuron Model with Softmax Activation\n","    Z = torch.softmax(X @ w + b, dim = 1)\n","    return Z\n","\n","# Check model\n","for X_batch, y_batch in data_iter(batch_size=10, features=X_train, labels=y_train):\n","    out_batch = model(X_batch, w, b)\n","    print('X_batch', X_batch.shape, X_batch[0])\n","    print('out_batch', out_batch.shape, out_batch[0])\n","    break"]},{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665372828511,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"},"user_tz":300},"id":"ViCDki3gFPVg"},"source":["**Training**"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697325716028,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"g0jpjWjTGP51"},"outputs":[],"source":["# Hyperparameters\n","lr = 0.01\n","batch_size = 10\n","num_epochs = 50"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":757,"status":"ok","timestamp":1697325716781,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"VYKa1O-iFDrK","outputId":"05d0ca94-0ada-4c2f-93f7-825798663151"},"outputs":[{"output_type":"stream","name":"stdout","text":["training epoch 1, loss 1.098999\n","training epoch 2, loss 1.083689\n","training epoch 3, loss 1.074124\n","training epoch 4, loss 1.066308\n","training epoch 5, loss 1.058918\n","training epoch 6, loss 1.051566\n","training epoch 7, loss 1.044101\n","training epoch 8, loss 1.036564\n","training epoch 9, loss 1.028840\n","training epoch 10, loss 1.021043\n","training epoch 11, loss 1.013317\n","training epoch 12, loss 1.005754\n","training epoch 13, loss 0.998234\n","training epoch 14, loss 0.991069\n","training epoch 15, loss 0.984047\n","training epoch 16, loss 0.977386\n","training epoch 17, loss 0.971036\n","training epoch 18, loss 0.965052\n","training epoch 19, loss 0.959222\n","training epoch 20, loss 0.953754\n","training epoch 21, loss 0.948671\n","training epoch 22, loss 0.943633\n","training epoch 23, loss 0.938953\n","training epoch 24, loss 0.934496\n","training epoch 25, loss 0.930282\n","training epoch 26, loss 0.926220\n","training epoch 27, loss 0.922386\n","training epoch 28, loss 0.918724\n","training epoch 29, loss 0.915227\n","training epoch 30, loss 0.911887\n","training epoch 31, loss 0.908690\n","training epoch 32, loss 0.905609\n","training epoch 33, loss 0.902721\n","training epoch 34, loss 0.899881\n","training epoch 35, loss 0.897225\n","training epoch 36, loss 0.894546\n","training epoch 37, loss 0.892047\n","training epoch 38, loss 0.889601\n","training epoch 39, loss 0.887340\n","training epoch 40, loss 0.885013\n","training epoch 41, loss 0.882818\n","training epoch 42, loss 0.880665\n","training epoch 43, loss 0.878601\n","training epoch 44, loss 0.876625\n","training epoch 45, loss 0.874687\n","training epoch 46, loss 0.872800\n","training epoch 47, loss 0.870971\n","training epoch 48, loss 0.869205\n","training epoch 49, loss 0.867474\n","training epoch 50, loss 0.865784\n"]}],"source":["# Learning\n","# Initialize the parameters of the model\n","torch.nn.init.normal_(w, mean=0, std=0.01)\n","torch.nn.init.zeros_(b)\n","\n","y_train = y_train.long()\n","\n","for epoch in range(num_epochs):\n","    with torch.no_grad():\n","        train_loss = cross_entropy(model(X_train, w, b), y_train)\n","        print(f'training epoch {epoch + 1}, loss {float(train_loss):f}')\n","\n","    # Train for one epoch\n","    for X_batch, y_batch in data_iter(batch_size=10, features=X_train, labels=y_train):\n","        # Use model to compute predictions\n","        yhat = model(X_batch, w, b)\n","        loss = cross_entropy(yhat, y_batch)\n","\n","        # Compute gradients by back propagation\n","        loss.backward()\n","\n","        # Update parameters using their gradient\n","        sgd([w, b], [w.grad, b.grad], lr)\n","\n","        # Reset gradients\n","        w.grad = b.grad = None"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1697325716782,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"},"user_tz":300},"id":"THNnf8ERXqE7","outputId":"79a42a58-448c-47fa-cbcc-f73e9d19a317"},"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[11  0  0]\n"," [ 0  0  8]\n"," [ 0  0 11]]\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","yhat = model(X_test, w, b).argmax(dim=1)\n","conf_matrix = confusion_matrix(y_test, yhat)\n","\n","print('Confusion Matrix:\\n', conf_matrix)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}