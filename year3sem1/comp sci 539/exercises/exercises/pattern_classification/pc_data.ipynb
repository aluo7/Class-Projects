{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"vfwQ6YEhluba","executionInfo":{"status":"ok","timestamp":1697158274114,"user_tz":300,"elapsed":16,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}}},"outputs":[],"source":["# from google.colab import drive\n","import numpy as np\n","\n","# makes printing more human-friendly\n","np.set_printoptions(precision=3,suppress=True)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"xSTFp8iXyCNm","executionInfo":{"status":"ok","timestamp":1697158294685,"user_tz":300,"elapsed":20584,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"outputId":"3cb259e7-5b7f-4cb7-aa0f-eb9114618311","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GCRLZQyrnyMo","executionInfo":{"status":"ok","timestamp":1697158328879,"user_tz":300,"elapsed":889,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"outputId":"1498e150-9b4d-4631-f324-a2b66f4ef527"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["array([59, 71, 48])"]},"metadata":{},"execution_count":7}],"source":["# a) Load data\n","from google.colab import drive\n","\n","colab = True  # Set to True if using colab\n","if colab:\n","    # May require changing paths to file\n","    drive.mount('/content/drive')\n","    with open('/content/drive/MyDrive/Colab Notebooks/data/Ex_PC_data.csv', 'r') as f:\n","      data = np.genfromtxt(f,delimiter=',')\n","else:\n","    # May require changing paths to file\n","    with open('Ex_PC_data.csv', 'r') as f:\n","      data = np.genfromtxt(f,delimiter=',')\n","\n","X = data[:,:-1]\n","y = data[:,-1]\n","\n","unique_values, counts = np.unique(y, return_counts=True)\n","counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ga08Oc2ZnwqK","executionInfo":{"status":"ok","timestamp":1694985237346,"user_tz":300,"elapsed":4,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"369dcd2b-b5a7-4e97-8501-bf8101ac18ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["num of samples: 178\n","num of feature dimensions: 13\n","num of classes: 3\n","class 1.0 has 59 samples\n","class 2.0 has 71 samples\n","class 3.0 has 48 samples\n"]}],"source":["# b) number of samples, features dimension, the number of classes\n","\n","num_samples = len(X)\n","num_feats = len(data[0]) - 1\n","num_classes = len(np.unique(y))\n","num_samples_per_class = {value: count for value, count in zip(unique_values, counts)}\n","\n","print(f'num of samples: {num_samples}')\n","print(f'num of feature dimensions: {num_feats}')\n","print(f'num of classes: {num_classes}')\n","for cls in num_samples_per_class:\n","  print(f'class {cls} has {num_samples_per_class[cls]} samples')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZpvsgo2oXIb","executionInfo":{"status":"ok","timestamp":1694985238893,"user_tz":300,"elapsed":1549,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"da6e9c3a-67d5-46ca-9ae6-30bf391917e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total of NaN before imputation: 6\n","Total of NaN after imputation: 0\n"]}],"source":["# c) check nan, data imputation\n","from sklearn.impute import KNNImputer\n","\n","if np.sum(np.isnan(X)):\n","  print('Total of NaN before imputation:', np.sum(np.isnan(X)))\n","  X = KNNImputer(n_neighbors=2, weights=\"uniform\").fit_transform(X)\n","  print('Total of NaN after imputation:', np.sum(np.isnan(X)))\n","else:\n","  print('no NaN')"]},{"cell_type":"markdown","metadata":{"id":"oVPThohanyMp"},"source":["#### Q) How are the missing values completed when using KNNImputer?\n","A) it seems like they're computed by using KNN. it uses the mean of the n_neighbors nearest neighbors from the training set (which was 2 in this case), and replaces the NaN value with that calculated mean."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Ue36ENusGef","executionInfo":{"status":"ok","timestamp":1694985238893,"user_tz":300,"elapsed":5,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a13677a9-38f9-4337-9b5a-64b090d882e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["training data size:  142\n","testing data size:  36\n"]}],"source":["# d) partition 80/20\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n","\n","print('training data size: ', X_train.shape[0])\n","print('testing data size: ', X_test.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnkQ2QfWvO44","executionInfo":{"status":"ok","timestamp":1694985239067,"user_tz":300,"elapsed":177,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"980368e7-3830-430c-ae40-6185b3541ec5"},"outputs":[{"output_type":"stream","name":"stdout","text":["min training data in each dimension, after standardization: [-5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5.]\n","max training data in each dimension, after standardization: [5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n","min testing data in each dimension, after standardization: [-5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5.]\n","max testing data in each dimension, after standardization: [5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n"]}],"source":["# e) standardize to -5 to 5\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler(feature_range=(-5, 5))\n","\n","X_train_min = np.min(X_train)\n","X_train_max = np.max(X_train)\n","X_train_standardized = scaler.fit_transform(X_train)\n","print('min training data in each dimension, after standardization:', np.min(X_train_standardized, axis=0))\n","print('max training data in each dimension, after standardization:', np.max(X_train_standardized, axis=0))\n","\n","# Warning: When standardizing the test set, we should use statistics like min or max computed from the training set.\n","X_test_standardized = scaler.fit_transform(X_test)\n","print('min testing data in each dimension, after standardization:', np.min(X_test_standardized, axis=0))\n","print('max testing data in each dimension, after standardization:', np.max(X_test_standardized, axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CIY5KbsnyMq","executionInfo":{"status":"ok","timestamp":1694985239262,"user_tz":300,"elapsed":5,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf363501-3ae0-4825-9ee2-15660fe7f707"},"outputs":[{"output_type":"stream","name":"stdout","text":["mean training data in each dimension, after standardization: [ 0. -0.  0.  0. -0. -0. -0.  0. -0.  0. -0. -0.  0.]\n","std training data in each dimension, after standardization: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n","mean testing data in each dimension, after standardization: [-0. -0. -0. -0.  0.  0. -0.  0. -0.  0. -0.  0.  0.]\n","std testing data in each dimension, after standardization: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"]}],"source":["# f) standardize to 0 mean, unit variance\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","\n","X_train_mean = np.mean(X_train)\n","X_train_std = np.std(X_train)\n","X_train_standardized = scaler.fit_transform(X_train)\n","print('mean training data in each dimension, after standardization:', np.mean(X_train_standardized, axis=0))\n","print('std training data in each dimension, after standardization:', np.std(X_train_standardized, axis=0))\n","\n","# Warning: When standardizing the test set, we should use statistics like min or max computed from the training set.\n","X_test_standardized = scaler.fit_transform(X_test)\n","print('mean testing data in each dimension, after standardization:', np.mean(X_test_standardized, axis=0))\n","print('std testing data in each dimension, after standardization:', np.std(X_test_standardized, axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhMyvX7TxO5S","executionInfo":{"status":"ok","timestamp":1694985239262,"user_tz":300,"elapsed":3,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"66bfd644-9d33-44c7-bab9-732bdb8f43b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 0:\n","  Train: index=[ 29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46\n","  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64\n","  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n","  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100\n"," 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n"," 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n"," 137 138 139 140 141]\n","  Test:  index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28]\n","Fold 1:\n","  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  58  59  60  61  62  63  64\n","  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n","  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100\n"," 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n"," 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n"," 137 138 139 140 141]\n","  Test:  index=[29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n"," 53 54 55 56 57]\n","Fold 2:\n","  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n","  54  55  56  57  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n"," 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n"," 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n"," 136 137 138 139 140 141]\n","  Test:  index=[58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n"," 82 83 84 85]\n","Fold 3:\n","  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n","  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n","  72  73  74  75  76  77  78  79  80  81  82  83  84  85 114 115 116 117\n"," 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n"," 136 137 138 139 140 141]\n","  Test:  index=[ 86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n"," 104 105 106 107 108 109 110 111 112 113]\n","Fold 4:\n","  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n","  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n","  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n","  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n"," 108 109 110 111 112 113]\n","  Test:  index=[114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n"," 132 133 134 135 136 137 138 139 140 141]\n"]}],"source":["# g) k fold\n","from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits = 5)\n","\n","# Count the class distributions in each partition\n","for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n","  print(f\"Fold {i}:\")\n","  print(f\"  Train: index={train_index}\")\n","  print(f\"  Test:  index={val_index}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqtiN5sX2ER7"},"outputs":[],"source":["if colab:\n","    drive.flush_and_unmount()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}