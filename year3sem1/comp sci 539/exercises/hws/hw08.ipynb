{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHYf6yPYOkGNZAmsHtwTSz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"qKfK7_GJ7nMj","executionInfo":{"status":"ok","timestamp":1698625765767,"user_tz":300,"elapsed":7341,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"outputId":"b5590dc9-a43a-4441-8176-becacefca7f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","drive.mount('/content/drive')\n","with open('/content/drive/MyDrive/Colab Notebooks/data/winequality-white.csv', 'r') as f:\n","  data = np.genfromtxt(f, delimiter=',', skip_header=1)\n","\n","X = data[:, :-1]\n","y = data[:, -1]"]},{"cell_type":"code","source":["y_one_hot = to_categorical(y - 3)\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"],"metadata":{"id":"zna7dTzN7zRD","executionInfo":{"status":"ok","timestamp":1698625765767,"user_tz":300,"elapsed":4,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_one_hot, test_size=0.4, stratify=y_one_hot.argmax(1))\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp.argmax(1))"],"metadata":{"id":"nwzklXI88V93","executionInfo":{"status":"ok","timestamp":1698625765929,"user_tz":300,"elapsed":2,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Build the model\n","H = 64  # Number of neurons in the hidden layers, replace with desired number\n","model = Sequential([\n","    Dense(H, activation='relu', input_shape=(11,)),\n","    Dense(H, activation='relu'),\n","    Dense(H, activation='relu'),\n","    Dense(H, activation='relu'),\n","    Dense(7, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"cd5PC0P88f1g","executionInfo":{"status":"ok","timestamp":1698625766435,"user_tz":300,"elapsed":507,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#train the model\n","\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_val, y_val),\n","    epochs=100,\n","    verbose=1\n",")\n","\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","final_loss_value = history.history['loss'][-1]\n","final_val_loss_value = history.history['val_loss'][-1]\n","\n","print(f\"Final training loss value: {final_loss_value}\")\n","print(f\"Final validation loss value: {final_val_loss_value}\")\n","print(f\"Test accuracy: {test_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"nDwuayrE9M7U","executionInfo":{"status":"ok","timestamp":1698625811859,"user_tz":300,"elapsed":45428,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"outputId":"7b1d79b4-5c6a-4b17-a381-b5b75825226c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","92/92 [==============================] - 5s 8ms/step - loss: 1.3036 - accuracy: 0.4877 - val_loss: 1.1794 - val_accuracy: 0.5235\n","Epoch 2/100\n","92/92 [==============================] - 0s 4ms/step - loss: 1.1018 - accuracy: 0.5490 - val_loss: 1.1495 - val_accuracy: 0.4806\n","Epoch 3/100\n","92/92 [==============================] - 0s 3ms/step - loss: 1.0463 - accuracy: 0.5660 - val_loss: 1.1045 - val_accuracy: 0.5265\n","Epoch 4/100\n","92/92 [==============================] - 0s 3ms/step - loss: 1.0176 - accuracy: 0.5725 - val_loss: 1.1046 - val_accuracy: 0.5133\n","Epoch 5/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.9905 - accuracy: 0.5902 - val_loss: 1.0895 - val_accuracy: 0.5245\n","Epoch 6/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.9656 - accuracy: 0.5865 - val_loss: 1.0949 - val_accuracy: 0.5102\n","Epoch 7/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.9545 - accuracy: 0.5929 - val_loss: 1.0700 - val_accuracy: 0.5204\n","Epoch 8/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.9364 - accuracy: 0.6014 - val_loss: 1.0821 - val_accuracy: 0.5082\n","Epoch 9/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.6116 - val_loss: 1.0691 - val_accuracy: 0.5235\n","Epoch 10/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.9126 - accuracy: 0.6263 - val_loss: 1.0724 - val_accuracy: 0.5378\n","Epoch 11/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.9013 - accuracy: 0.6144 - val_loss: 1.0690 - val_accuracy: 0.5071\n","Epoch 12/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.8794 - accuracy: 0.6304 - val_loss: 1.0665 - val_accuracy: 0.5378\n","Epoch 13/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.8551 - accuracy: 0.6487 - val_loss: 1.0781 - val_accuracy: 0.5122\n","Epoch 14/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.6481 - val_loss: 1.0754 - val_accuracy: 0.5194\n","Epoch 15/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.8256 - accuracy: 0.6552 - val_loss: 1.1203 - val_accuracy: 0.5398\n","Epoch 16/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.8188 - accuracy: 0.6613 - val_loss: 1.0848 - val_accuracy: 0.5265\n","Epoch 17/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.7986 - accuracy: 0.6732 - val_loss: 1.1633 - val_accuracy: 0.5378\n","Epoch 18/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.7869 - accuracy: 0.6797 - val_loss: 1.0921 - val_accuracy: 0.5327\n","Epoch 19/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.6950 - val_loss: 1.1261 - val_accuracy: 0.5510\n","Epoch 20/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.6950 - val_loss: 1.1501 - val_accuracy: 0.5235\n","Epoch 21/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.7093 - val_loss: 1.1415 - val_accuracy: 0.5500\n","Epoch 22/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.7166 - accuracy: 0.7134 - val_loss: 1.1521 - val_accuracy: 0.5347\n","Epoch 23/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.7110 - val_loss: 1.1432 - val_accuracy: 0.5408\n","Epoch 24/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.7178 - val_loss: 1.1494 - val_accuracy: 0.5469\n","Epoch 25/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.7386 - val_loss: 1.1481 - val_accuracy: 0.5551\n","Epoch 26/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.7400 - val_loss: 1.1855 - val_accuracy: 0.5398\n","Epoch 27/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7413 - val_loss: 1.1796 - val_accuracy: 0.5429\n","Epoch 28/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7560 - val_loss: 1.1680 - val_accuracy: 0.5622\n","Epoch 29/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7699 - val_loss: 1.2334 - val_accuracy: 0.5571\n","Epoch 30/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7716 - val_loss: 1.2354 - val_accuracy: 0.5480\n","Epoch 31/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7801 - val_loss: 1.2258 - val_accuracy: 0.5398\n","Epoch 32/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7886 - val_loss: 1.2478 - val_accuracy: 0.5469\n","Epoch 33/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7900 - val_loss: 1.3013 - val_accuracy: 0.5480\n","Epoch 34/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7900 - val_loss: 1.3738 - val_accuracy: 0.5582\n","Epoch 35/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.8016 - val_loss: 1.3090 - val_accuracy: 0.5418\n","Epoch 36/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.8097 - val_loss: 1.3466 - val_accuracy: 0.5571\n","Epoch 37/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.8108 - val_loss: 1.3255 - val_accuracy: 0.5582\n","Epoch 38/100\n","92/92 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.8196 - val_loss: 1.3732 - val_accuracy: 0.5469\n","Epoch 39/100\n","92/92 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.8315 - val_loss: 1.4158 - val_accuracy: 0.5684\n","Epoch 40/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.8206 - val_loss: 1.4670 - val_accuracy: 0.5357\n","Epoch 41/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8237 - val_loss: 1.4357 - val_accuracy: 0.5459\n","Epoch 42/100\n","92/92 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8339 - val_loss: 1.4475 - val_accuracy: 0.5378\n","Epoch 43/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8414 - val_loss: 1.4563 - val_accuracy: 0.5653\n","Epoch 44/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8424 - val_loss: 1.4906 - val_accuracy: 0.5418\n","Epoch 45/100\n","92/92 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8570 - val_loss: 1.4862 - val_accuracy: 0.5571\n","Epoch 46/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8468 - val_loss: 1.5469 - val_accuracy: 0.5469\n","Epoch 47/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8570 - val_loss: 1.5952 - val_accuracy: 0.5449\n","Epoch 48/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8662 - val_loss: 1.5777 - val_accuracy: 0.5510\n","Epoch 49/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8669 - val_loss: 1.6416 - val_accuracy: 0.5408\n","Epoch 50/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8713 - val_loss: 1.6142 - val_accuracy: 0.5429\n","Epoch 51/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8771 - val_loss: 1.6475 - val_accuracy: 0.5643\n","Epoch 52/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8836 - val_loss: 1.6453 - val_accuracy: 0.5490\n","Epoch 53/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8870 - val_loss: 1.7298 - val_accuracy: 0.5602\n","Epoch 54/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8819 - val_loss: 1.6989 - val_accuracy: 0.5684\n","Epoch 55/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.9013 - val_loss: 1.7510 - val_accuracy: 0.5612\n","Epoch 56/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.9027 - val_loss: 1.8486 - val_accuracy: 0.5612\n","Epoch 57/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.9003 - val_loss: 1.7727 - val_accuracy: 0.5582\n","Epoch 58/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8962 - val_loss: 1.8542 - val_accuracy: 0.5724\n","Epoch 59/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8958 - val_loss: 1.8614 - val_accuracy: 0.5724\n","Epoch 60/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.9166 - val_loss: 1.8979 - val_accuracy: 0.5398\n","Epoch 61/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9132 - val_loss: 1.9219 - val_accuracy: 0.5520\n","Epoch 62/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2402 - accuracy: 0.9173 - val_loss: 1.9567 - val_accuracy: 0.5520\n","Epoch 63/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9129 - val_loss: 1.9698 - val_accuracy: 0.5551\n","Epoch 64/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.9170 - val_loss: 1.9712 - val_accuracy: 0.5449\n","Epoch 65/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9272 - val_loss: 2.0269 - val_accuracy: 0.5418\n","Epoch 66/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9173 - val_loss: 2.0951 - val_accuracy: 0.5694\n","Epoch 67/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9295 - val_loss: 2.1370 - val_accuracy: 0.5571\n","Epoch 68/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9289 - val_loss: 2.1864 - val_accuracy: 0.5388\n","Epoch 69/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9319 - val_loss: 2.1376 - val_accuracy: 0.5602\n","Epoch 70/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9302 - val_loss: 2.1728 - val_accuracy: 0.5602\n","Epoch 71/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9394 - val_loss: 2.1594 - val_accuracy: 0.5592\n","Epoch 72/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9381 - val_loss: 2.2167 - val_accuracy: 0.5796\n","Epoch 73/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9418 - val_loss: 2.2505 - val_accuracy: 0.5724\n","Epoch 74/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9462 - val_loss: 2.3055 - val_accuracy: 0.5500\n","Epoch 75/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9455 - val_loss: 2.3391 - val_accuracy: 0.5510\n","Epoch 76/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9323 - val_loss: 2.3556 - val_accuracy: 0.5469\n","Epoch 77/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9404 - val_loss: 2.3613 - val_accuracy: 0.5561\n","Epoch 78/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9452 - val_loss: 2.3861 - val_accuracy: 0.5531\n","Epoch 79/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9438 - val_loss: 2.3440 - val_accuracy: 0.5704\n","Epoch 80/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9503 - val_loss: 2.3655 - val_accuracy: 0.5531\n","Epoch 81/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9564 - val_loss: 2.4774 - val_accuracy: 0.5561\n","Epoch 82/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9629 - val_loss: 2.5310 - val_accuracy: 0.5602\n","Epoch 83/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9585 - val_loss: 2.5393 - val_accuracy: 0.5612\n","Epoch 84/100\n","92/92 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9643 - val_loss: 2.6641 - val_accuracy: 0.5531\n","Epoch 85/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9561 - val_loss: 2.6650 - val_accuracy: 0.5551\n","Epoch 86/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9493 - val_loss: 2.6604 - val_accuracy: 0.5551\n","Epoch 87/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9415 - val_loss: 2.6178 - val_accuracy: 0.5714\n","Epoch 88/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9643 - val_loss: 2.6064 - val_accuracy: 0.5602\n","Epoch 89/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9673 - val_loss: 2.7490 - val_accuracy: 0.5714\n","Epoch 90/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9537 - val_loss: 2.6535 - val_accuracy: 0.5694\n","Epoch 91/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9755 - val_loss: 2.7366 - val_accuracy: 0.5684\n","Epoch 92/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9694 - val_loss: 2.8171 - val_accuracy: 0.5735\n","Epoch 93/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 0.9660 - val_loss: 2.8312 - val_accuracy: 0.5378\n","Epoch 94/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9622 - val_loss: 2.8127 - val_accuracy: 0.5612\n","Epoch 95/100\n","92/92 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.9711 - val_loss: 2.8625 - val_accuracy: 0.5755\n","Epoch 96/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9721 - val_loss: 2.9467 - val_accuracy: 0.5888\n","Epoch 97/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9704 - val_loss: 2.9282 - val_accuracy: 0.5755\n","Epoch 98/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9731 - val_loss: 2.9677 - val_accuracy: 0.5602\n","Epoch 99/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9595 - val_loss: 3.0244 - val_accuracy: 0.5663\n","Epoch 100/100\n","92/92 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9700 - val_loss: 3.1013 - val_accuracy: 0.5469\n","Final training loss value: 0.10744686424732208\n","Final validation loss value: 3.101270914077759\n","Test accuracy: 0.5642856955528259\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n","from tensorflow.keras.models import Model\n","\n","fashion_mnist = tf.keras.datasets.fashion_mnist\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","x_train = x_train.reshape((-1, 784))\n","x_test = x_test.reshape((-1, 784))\n","\n","input_img = Input(shape=(784,))\n","encoded = Dense(128, activation='relu')(input_img)\n","encoded = Dense(64, activation='relu')(encoded)\n","\n","decoded = Dense(128, activation='relu')(encoded)\n","decoded = Dense(784, activation='sigmoid')(decoded)\n","\n","autoencoder = Model(input_img, decoded)\n","\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Train the model\n","autoencoder.fit(x_train, x_train,\n","                epochs=50,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test))\n","\n","encoder = Model(input_img, encoded)\n","\n","encoded_imgs = encoder.predict(x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"van5RRZE-wxg","executionInfo":{"status":"ok","timestamp":1698626016767,"user_tz":300,"elapsed":204915,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}},"outputId":"52dab304-6005-44a0-a561-9da280e2cdaa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","235/235 [==============================] - 4s 13ms/step - loss: 0.3654 - val_loss: 0.3119\n","Epoch 2/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.3021 - val_loss: 0.2988\n","Epoch 3/50\n","235/235 [==============================] - 4s 16ms/step - loss: 0.2936 - val_loss: 0.2939\n","Epoch 4/50\n","235/235 [==============================] - 4s 17ms/step - loss: 0.2884 - val_loss: 0.2884\n","Epoch 5/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2849 - val_loss: 0.2855\n","Epoch 6/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2823 - val_loss: 0.2843\n","Epoch 7/50\n","235/235 [==============================] - 4s 16ms/step - loss: 0.2806 - val_loss: 0.2820\n","Epoch 8/50\n","235/235 [==============================] - 5s 20ms/step - loss: 0.2791 - val_loss: 0.2806\n","Epoch 9/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2780 - val_loss: 0.2798\n","Epoch 10/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2771 - val_loss: 0.2789\n","Epoch 11/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2762 - val_loss: 0.2782\n","Epoch 12/50\n","235/235 [==============================] - 5s 20ms/step - loss: 0.2754 - val_loss: 0.2772\n","Epoch 13/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2748 - val_loss: 0.2768\n","Epoch 14/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2741 - val_loss: 0.2762\n","Epoch 15/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2736 - val_loss: 0.2761\n","Epoch 16/50\n","235/235 [==============================] - 5s 19ms/step - loss: 0.2731 - val_loss: 0.2750\n","Epoch 17/50\n","235/235 [==============================] - 3s 14ms/step - loss: 0.2726 - val_loss: 0.2747\n","Epoch 18/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2722 - val_loss: 0.2743\n","Epoch 19/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2718 - val_loss: 0.2738\n","Epoch 20/50\n","235/235 [==============================] - 4s 17ms/step - loss: 0.2715 - val_loss: 0.2735\n","Epoch 21/50\n","235/235 [==============================] - 4s 15ms/step - loss: 0.2711 - val_loss: 0.2733\n","Epoch 22/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2708 - val_loss: 0.2732\n","Epoch 23/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2705 - val_loss: 0.2728\n","Epoch 24/50\n","235/235 [==============================] - 3s 15ms/step - loss: 0.2702 - val_loss: 0.2727\n","Epoch 25/50\n","235/235 [==============================] - 4s 18ms/step - loss: 0.2700 - val_loss: 0.2722\n","Epoch 26/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2697 - val_loss: 0.2722\n","Epoch 27/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2696 - val_loss: 0.2719\n","Epoch 28/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2693 - val_loss: 0.2716\n","Epoch 29/50\n","235/235 [==============================] - 5s 20ms/step - loss: 0.2691 - val_loss: 0.2714\n","Epoch 30/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2689 - val_loss: 0.2713\n","Epoch 31/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2687 - val_loss: 0.2713\n","Epoch 32/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2686 - val_loss: 0.2709\n","Epoch 33/50\n","235/235 [==============================] - 5s 19ms/step - loss: 0.2684 - val_loss: 0.2708\n","Epoch 34/50\n","235/235 [==============================] - 3s 14ms/step - loss: 0.2683 - val_loss: 0.2706\n","Epoch 35/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2682 - val_loss: 0.2705\n","Epoch 36/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2680 - val_loss: 0.2704\n","Epoch 37/50\n","235/235 [==============================] - 4s 17ms/step - loss: 0.2679 - val_loss: 0.2703\n","Epoch 38/50\n","235/235 [==============================] - 4s 15ms/step - loss: 0.2677 - val_loss: 0.2702\n","Epoch 39/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2677 - val_loss: 0.2702\n","Epoch 40/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2676 - val_loss: 0.2704\n","Epoch 41/50\n","235/235 [==============================] - 3s 15ms/step - loss: 0.2674 - val_loss: 0.2698\n","Epoch 42/50\n","235/235 [==============================] - 4s 18ms/step - loss: 0.2673 - val_loss: 0.2699\n","Epoch 43/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2673 - val_loss: 0.2697\n","Epoch 44/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2671 - val_loss: 0.2696\n","Epoch 45/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2670 - val_loss: 0.2695\n","Epoch 46/50\n","235/235 [==============================] - 5s 20ms/step - loss: 0.2669 - val_loss: 0.2695\n","Epoch 47/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2670 - val_loss: 0.2694\n","Epoch 48/50\n","235/235 [==============================] - 3s 12ms/step - loss: 0.2668 - val_loss: 0.2692\n","Epoch 49/50\n","235/235 [==============================] - 3s 13ms/step - loss: 0.2667 - val_loss: 0.2692\n","Epoch 50/50\n","235/235 [==============================] - 5s 19ms/step - loss: 0.2666 - val_loss: 0.2691\n","313/313 [==============================] - 1s 2ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"U2jxGRYa-yhU","executionInfo":{"status":"ok","timestamp":1698626016767,"user_tz":300,"elapsed":17,"user":{"displayName":"ALAN LUO","userId":"02234547579346071235"}}},"execution_count":6,"outputs":[]}]}